{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Tensorflow Tutorial 1: Simple Logistic Classification on MNIST\n",
    "\n",
    "åˆæ¬¡å­¸ç¿’Tensorflowæœ€å›°é›£çš„åœ°æ–¹è«éæ–¼ä¸çŸ¥é“å¾ä½•ä¸‹æ‰‹ï¼Œå·²ç¶“å­¸æœƒå¾ˆå¤šçš„Deep Learningç†è«–ï¼Œä½†æ˜¯è¦è‡ªå·±ä½¿ç”¨Tensorflowå°‡Networkå»ºèµ·ä¾†å»æ˜¯éå¸¸å›°é›£çš„ï¼Œé€™ç¯‡æ–‡ç« æˆ‘æœƒå…ˆç°¡å–®çš„ä»‹ç´¹å¹¾å€‹Tensorflowçš„æ¦‚å¿µï¼Œæœ€å¾Œåˆ©ç”¨é€™äº›æ¦‚å¿µå»ºç«‹ä¸€å€‹ç°¡å–®çš„åˆ†é¡æ¨¡å‹ã€‚\n",
    "\n",
    "æœ¬å–®å…ƒç¨‹å¼ç¢¼å¯æ–¼[Github]( https://github.com/GitYCC/Tensorflow_Tutorial/blob/master/code/01_simple_logistic_classification_on_MNIST.py)ä¸‹è¼‰ã€‚\n",
    "\n",
    "### MNIST Dataset\n",
    "\n",
    "é¦–å…ˆï¼Œå…ˆ`import`ä¸€äº›æœƒç”¨åˆ°çš„functionï¼Œä¸¦ä¸”å®šç¾©`summary` functionä»¥ä¾¿æ–¼è§€å¯Ÿndarrayã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline\n",
    "\n",
    "def summary(ndarr):\n",
    "    print(ndarr)\n",
    "    print(\"* shape: {}\".format(ndarr.shape))\n",
    "    print(\"* min: {}\".format(np.min(ndarr)))\n",
    "    print(\"* max: {}\".format(np.max(ndarr)))\n",
    "    print(\"* avg: {}\".format(np.mean(ndarr)))\n",
    "    print(\"* std: {}\".format(np.std(ndarr)))\n",
    "    print(\"* unique: {}\".format(np.unique(ndarr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ndarrayæ˜¯numpyçš„åŸºæœ¬å…ƒç´ ï¼Œå®ƒéå¸¸ä¾¿æ–¼æˆ‘å€‘åšçŸ©é™£çš„é‹ç®—ã€‚\n",
    "\n",
    "æˆ‘å€‘ä½¿ç”¨MNIST Datasetä¾†ç•¶ä½œæˆ‘å€‘ç·´ç¿’çš„æ¨™çš„ï¼ŒMNISTåŒ…å«ä¸€åŒ…æ‰‹å¯«æ•¸å­—çš„åœ–ç‰‡ï¼Œæ¯å¼µåœ–ç‰‡å¤§å°ç‚º28x28ï¼Œæ¯ä¸€å¼µåœ–ç‰‡éƒ½æ˜¯ä¸€å€‹æ‰‹å¯«çš„é˜¿æ‹‰ä¼¯æ•¸å­—åŒ…å«0åˆ°9ï¼Œä¸¦ä¸”æ¨™è¨˜ä¸Šå®ƒæ‰€å°æ‡‰çš„æ•¸å­—ã€‚æˆ‘å€‘çš„ç›®æ¨™å°±æ˜¯è¦åˆ©ç”¨MNISTåšåˆ°æ‰‹å¯«æ•¸å­—è¾¨è­˜ã€‚\n",
    "\n",
    "åœ¨Tensorflowä½ å¯ä»¥å¾ˆç°¡å–®çš„å¾—åˆ°ã€Œè™•ç†éå¾Œçš„ã€MNISTï¼Œåªè¦åˆ©ç”¨ä»¥ä¸‹ç¨‹å¼ç¢¼ï¼Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "train_data = mnist.train\n",
    "valid_data = mnist.validation\n",
    "test_data = mnist.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¯å€‹`train_data`ã€`valid_data`ã€`test_data`éƒ½åŒ…å«å…©éƒ¨åˆ†ï¼šåœ–ç‰‡å’Œæ¨™ç±¤ã€‚\n",
    "\n",
    "æˆ‘å€‘ä¾†çœ‹ä¸€ä¸‹åœ–ç‰‡çš„éƒ¨åˆ†ï¼Œ`train_data.images`ä¸€å…±æœ‰55000å¼µåœ–ï¼Œæ¯ä¸€å¼µåœ–åŸæœ¬å¤§å°æ˜¯28x28ï¼Œä¸éç‰¹åˆ¥æ³¨æ„é€™è£¡çš„Dataå·²ç¶“å…ˆåšéé å…ˆè™•ç†äº†ï¼Œå› æ­¤åœ–ç‰‡å·²ç¶“è¢«æ‰“å¹³æˆ28x28=784çš„ä¸€ç¶­çŸ©é™£äº†ï¼Œå¦å¤–æ¯å€‹Pixelçš„å€¼ä¹Ÿå…ˆåšéã€ŒNormalizationã€äº†ï¼Œé€šå¸¸æœƒé€™æ¨£è™•ç†ï¼Œæ¯å€‹å€¼æ¸›å»128å†é™¤ä»¥128ï¼Œæ‰€ä»¥ä½ å¯ä»¥å¾ä»¥ä¸‹çš„`summary`ä¸­çœ‹åˆ°å®ƒçš„æœ€å¤§æœ€å°å€¼è½åœ¨0åˆ°1ä¹‹é–“ï¼Œé‚„æœ‰é€™å€‹Datasetä¹Ÿå·²ç¶“åšéäº‚æ•¸é‡æ’äº†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "* shape: (55000, 784)\n",
      "* min: 0.0\n",
      "* max: 1.0\n",
      "* avg: 0.13070042431354523\n",
      "* std: 0.30815958976745605\n",
      "* unique: [ 0.          0.00392157  0.00784314  0.01176471  0.01568628  0.01960784\n",
      "  0.02352941  0.02745098  0.03137255  0.03529412  0.03921569  0.04313726\n",
      "  0.04705883  0.0509804   0.05490196  0.05882353  0.0627451   0.06666667\n",
      "  0.07058824  0.07450981  0.07843138  0.08235294  0.08627451  0.09019608\n",
      "  0.09411766  0.09803922  0.10196079  0.10588236  0.10980393  0.1137255\n",
      "  0.11764707  0.12156864  0.1254902   0.12941177  0.13333334  0.13725491\n",
      "  0.14117648  0.14509805  0.14901961  0.15294118  0.15686275  0.16078432\n",
      "  0.16470589  0.16862746  0.17254902  0.17647059  0.18039216  0.18431373\n",
      "  0.18823531  0.19215688  0.19607845  0.20000002  0.20392159  0.20784315\n",
      "  0.21176472  0.21568629  0.21960786  0.22352943  0.227451    0.23137257\n",
      "  0.23529413  0.2392157   0.24313727  0.24705884  0.25098041  0.25490198\n",
      "  0.25882354  0.26274511  0.26666668  0.27058825  0.27450982  0.27843139\n",
      "  0.28235295  0.28627452  0.29019609  0.29411766  0.29803923  0.3019608\n",
      "  0.30588236  0.30980393  0.3137255   0.31764707  0.32156864  0.32549021\n",
      "  0.32941177  0.33333334  0.33725491  0.34117648  0.34509805  0.34901962\n",
      "  0.35294119  0.35686275  0.36078432  0.36470589  0.36862746  0.37254903\n",
      "  0.37647063  0.38039219  0.38431376  0.38823533  0.3921569   0.39607847\n",
      "  0.40000004  0.4039216   0.40784317  0.41176474  0.41568631  0.41960788\n",
      "  0.42352945  0.42745101  0.43137258  0.43529415  0.43921572  0.44313729\n",
      "  0.44705886  0.45098042  0.45490199  0.45882356  0.46274513  0.4666667\n",
      "  0.47058827  0.47450984  0.4784314   0.48235297  0.48627454  0.49019611\n",
      "  0.49411768  0.49803925  0.50196081  0.50588238  0.50980395  0.51372552\n",
      "  0.51764709  0.52156866  0.52549022  0.52941179  0.53333336  0.53725493\n",
      "  0.5411765   0.54509807  0.54901963  0.5529412   0.55686277  0.56078434\n",
      "  0.56470591  0.56862748  0.57254905  0.57647061  0.58039218  0.58431375\n",
      "  0.58823532  0.59215689  0.59607846  0.60000002  0.60392159  0.60784316\n",
      "  0.61176473  0.6156863   0.61960787  0.62352943  0.627451    0.63137257\n",
      "  0.63529414  0.63921571  0.64313728  0.64705884  0.65098041  0.65490198\n",
      "  0.65882355  0.66274512  0.66666669  0.67058825  0.67450982  0.67843139\n",
      "  0.68235296  0.68627453  0.6901961   0.69411767  0.69803923  0.7019608\n",
      "  0.70588237  0.70980394  0.71372551  0.71764708  0.72156864  0.72549021\n",
      "  0.72941178  0.73333335  0.73725492  0.74117649  0.74509805  0.74901962\n",
      "  0.75294125  0.75686282  0.76078439  0.76470596  0.76862752  0.77254909\n",
      "  0.77647066  0.78039223  0.7843138   0.78823537  0.79215693  0.7960785\n",
      "  0.80000007  0.80392164  0.80784321  0.81176478  0.81568635  0.81960791\n",
      "  0.82352948  0.82745105  0.83137262  0.83529419  0.83921576  0.84313732\n",
      "  0.84705889  0.85098046  0.85490203  0.8588236   0.86274517  0.86666673\n",
      "  0.8705883   0.87450987  0.87843144  0.88235301  0.88627458  0.89019614\n",
      "  0.89411771  0.89803928  0.90196085  0.90588242  0.90980399  0.91372555\n",
      "  0.91764712  0.92156869  0.92549026  0.92941183  0.9333334   0.93725497\n",
      "  0.94117653  0.9450981   0.94901967  0.95294124  0.95686281  0.96078438\n",
      "  0.96470594  0.96862751  0.97254908  0.97647065  0.98039222  0.98431379\n",
      "  0.98823535  0.99215692  0.99607849  1.        ]\n"
     ]
    }
   ],
   "source": [
    "summary(train_data.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¾†è©¦è‘—ç•«åœ–ä¾†çœ‹çœ‹ï¼Œæˆ‘å€‘ä½¿ç”¨ndarrayçš„indexåŠŸèƒ½ä¾†é¸å‡ºç¬¬10å¼µåœ–ç‰‡ï¼Œ`train_data.images[10,:]`è¡¨ç¤ºçš„æ˜¯é¸ç¬¬ä¸€è»¸çš„ç¬¬10å€‹å’Œç¬¬äºŒè»¸çš„å…¨éƒ¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fatten_img(ndarr):\n",
    "    img = ndarr.copy()\n",
    "    img.shape = (28,28)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB4Ii/EBQhB8I6v8A+Md7QMI5IyUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11aa1bda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_fatten_img(train_data.images[10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¾ˆé¡¯è€Œæ˜“è¦‹çš„ï¼Œé€™æ˜¯ä¸€å€‹0ã€‚\n",
    "\n",
    "æ¥ä¸‹ä¾†ä¾†çœ‹æ¨™ç±¤çš„éƒ¨åˆ†ï¼Œ`train_data.labels`ä¸æ„å¤–çš„ä¸€æ¨£çš„ä¹Ÿæ˜¯æœ‰ç›¸æ‡‰çš„55000ç­†è³‡æ–™ï¼Œæ‰€å°æ‡‰çš„å°±æ˜¯å‰é¢çš„æ¯ä¸€å¼µåœ–ç‰‡ï¼Œç¸½å…±æœ‰10ç¨®é¡å‹:0åˆ°9ï¼Œæ‰€ä»¥å¤§å°ç‚º(55000, 10)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  1.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]]\n",
      "* shape: (55000, 10)\n",
      "* min: 0.0\n",
      "* max: 1.0\n",
      "* avg: 0.1\n",
      "* std: 0.30000000000000004\n",
      "* unique: [ 0.  1.]\n"
     ]
    }
   ],
   "source": [
    "summary(train_data.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ‰€ä»¥æˆ‘å€‘ä¾†çœ‹çœ‹ä¸Šé¢é‚£å¼µåœ–ç‰‡çš„æ¨™ç±¤ï¼Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(train_data.labels[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "çœ‹èµ·ä¾†çš„ç¢ºæ²’éŒ¯ï¼Œåœ¨0çš„ä½ç½®æ¨™ç¤º1.ï¼Œè€Œå…¶ä»–åœ°æ–¹æ¨™ç¤ºç‚º0.ï¼Œå› æ­¤é€™æ˜¯ä¸€å€‹æ¨™ç¤ºç‚º0çš„labelæ²’æœ‰éŒ¯ï¼Œé€™ç¨®è¡¨ç¤ºæ–¹æ³•ç¨±ç‚ºOne-Hot Encodingï¼Œå®ƒå…·æœ‰æ©Ÿç‡çš„æ¶µç¾©ï¼Œæ‰€ä»£è¡¨çš„æ˜¯æœ‰100%çš„æ©Ÿæœƒè½åœ¨0çš„é¡åˆ¥ä¸Šã€‚\n",
    "\n",
    "### Softmax\n",
    "\n",
    "é€šå¸¸One-Hot Encodingæœƒæ­é…Softmaxä¸€åŒæœç”¨ï¼Œæœ€å¾Œçš„Outputçµæœå¦‚æœæ˜¯æ©Ÿç‡åˆ†å¸ƒï¼Œé‚£æˆ‘ä¹Ÿéœ€è¦è®“æˆ‘çš„Neurel Networkå¯ä»¥è¼¸å‡ºæ©Ÿç‡åˆ†å¸ƒã€‚\n",
    "\n",
    "![softmax](https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/TensorflowTutorial.001.jpeg)\n",
    "\n",
    "é€šéSoftmaxé€™ä¸€å±¤ï¼Œæˆ‘å€‘å°±å¯ä»¥å°‡è¼¸å‡ºè½‰è®Šç‚ºä»¥ã€Œæ©Ÿç‡ã€è¡¨ç¤ºã€‚\n",
    "\n",
    "æˆ‘å€‘å¯ä»¥ä¾†æ‰‹åˆ»ä¸€å€‹Softmax Functionï¼Œä¸éç›´æ¥å¥—ç”¨Tensorflowä¸­å‡½æ•¸çš„ä¹Ÿæ˜¯å¯ä»¥çš„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8360188   0.11314284  0.05083836]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    # avoid exp function go to too large,\n",
    "    # pre-reduce before applying exp function\n",
    "    max_score = np.max(x,axis=0)\n",
    "    x = x - max_score\n",
    "    \n",
    "    exp_s = np.exp(x)\n",
    "    sum_exp_s = np.sum(exp_s,axis=0)\n",
    "    softmax = exp_s / sum_exp_s\n",
    "    return softmax\n",
    "\n",
    "scores = [3.0, 1.0, 0.2]\n",
    "print(softmax(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Entropy Loss\n",
    "\n",
    "ä¸€æ—¦æˆ‘å€‘è¦è™•ç†æ©Ÿç‡é æ¸¬çš„å•é¡Œï¼Œå°±ä¸å¯ä»¥ä½¿ç”¨å–®ç´”çš„ã€Œå¹³æ–¹èª¤å·®ã€ï¼Œè€Œå¿…é ˆä½¿ç”¨Cross-Entropy Lossï¼Œæ˜¯é€™æ¨£è¨ˆç®—çš„ï¼š\n",
    "\n",
    "Cross-Entropy Loss = -ğšº<sub>i</sub> y<sub>i</sub> ln[ s<sub>i</sub> ]\n",
    "\n",
    "å…¶ä¸­ï¼Œy<sub>i</sub>ç‚ºç›®æ¨™Labelï¼Œs<sub>i</sub>ç‚ºç¶“éSoftmaxç”¢ç”Ÿçš„é æ¸¬å€¼ã€‚\n",
    "\n",
    "è‡³æ–¼å¦‚æœä½ æƒ³è¦äº†è§£ç‚ºä½•éœ€è¦ä½¿ç”¨Cross-Entropy Lossï¼Ÿé€™æˆ‘åœ¨æ©Ÿå™¨å­¸ç¿’åŸºçŸ³çš„ç­†è¨˜ä¸­å·²ç¶“æœ‰æåŠéï¼Œè«‹çœ‹[ä»‹ç´¹Logistic Regressionçš„éƒ¨åˆ†](http://www.ycc.idv.tw/YCNote/post/27)ã€‚\n",
    "\n",
    "### åˆ†é›¢æ•¸æ“šçš„é‡è¦æ€§\n",
    "\n",
    "åœ¨MNIST Datasetä¸­ï¼Œä½ æœƒç™¼ç¾åˆ†ç‚ºTraining Datasetã€Validation Datasetå’ŒTesting Datasetï¼Œé€™æ¨£çš„ä½œæ³•åœ¨Machine Learningä¸­æ˜¯å¸¸è¦‹ä¸”å¿…è¦çš„ã€‚\n",
    "\n",
    "æµç¨‹æ˜¯é€™æ¨£çš„ï¼Œæˆ‘å€‘æœƒå…ˆä½¿ç”¨Training Datasetä¾†è¨“ç·´Modelï¼Œä¸¦ä¸”ä½¿ç”¨Validation Datasetä¾†æª¢é©—Modelçš„å¥½å£ï¼Œæˆ‘å€‘æœƒä¾æ“šValidation Datasetçš„æª¢é©—èª¿æ•´Modelä¸Šçš„åƒæ•¸ï¼Œè©¦è‘—ç›¡å¯èƒ½çš„å£“ä½Validation Datasetçš„Errorï¼Œè¨˜ä½ï¼åœ¨éç¨‹ä¸­æ‰€ç”¢ç”Ÿçš„æ‰€æœ‰Modelséƒ½è¦ä¿ç•™ä¸‹ä¾†ï¼Œå› ç‚ºæœ€å¾Œé¸æ“‡çš„Modelä¸¦ä¸æ˜¯Validation Datasetçš„Erroræœ€å°çš„ï¼Œè€Œæ˜¯è¦å†ç”±Testing Datasetä¾†åšæœ€å¾Œçš„æŒ‘é¸ï¼ŒæŒ‘é¸å‡ºèƒ½ä½¿Testing Datasetçš„Erroræœ€å°çš„Modelã€‚\n",
    "\n",
    "é€™æ‰€æœ‰çš„ä½œæ³•éƒ½æ˜¯ç‚ºäº†é¿å…Overfittingçš„æƒ…æ³ç™¼ç”Ÿï¼Œä¹Ÿå°±æ˜¯æ©Ÿå™¨å¯èƒ½å› ç‚ºçœ‹éä¸€ç­†Dataï¼Œçµæœå°±æŠŠé€™ç­†Dataçµ¦å®Œæ•´è¨˜äº†èµ·ä¾†ï¼Œè€ŒDataæœ¬èº«å«æœ‰é›œè¨Šï¼Œé›œè¨Šå°±é€™æ¨£æ»²é€åˆ°Modelè£¡ï¼Œç¢ºå¯¦åšåˆ°åˆ†é›¢æ˜¯å¾ˆé‡è¦çš„ï¼Œè®“Modelåœ¨æ¸¬è©¦éšæ®µæ™‚å¯ä»¥ä½¿ç”¨æ²’æœ‰çœ‹éçš„Dataã€‚\n",
    "\n",
    "å› æ­¤ï¼ŒValidation Datasetçš„åˆ†é›¢æ˜¯ç‚ºäº†é¿å…è®“Modelåœ¨Trainingéšæ®µçœ‹åˆ°è¦é©—è­‰çš„è³‡æ–™ï¼Œæ‰€ä»¥æ›´èƒ½æ­£ç¢ºçš„è©•ä¼°Modelçš„å¥½å£ã€‚ä½†é€™æ¨£æ˜¯ä¸å¤ çš„ï¼Œäººç‚ºæœƒæ ¹æ“šValidation Datasetä¾†èª¿æ•´Modelï¼Œé€™æ¨£ç„¡å½¢ä¹‹ä¸­å·²ç¶“å°‡Validation Datasetçš„è³‡è¨Šé–“æ¥çš„ç¶“ç”±äººå‚³çµ¦äº†Modelï¼Œæ‰€ä»¥é‚„æ˜¯æ²’æœ‰å¾¹åº•åˆ†é›¢ï¼Œå› æ­¤åœ¨æœ€å¾ŒæŒ‘é¸Modelsæ™‚ï¼Œæˆ‘å€‘æœƒä½¿ç”¨å¦å¤–ä¸€ç­†å¾æ²’çœ‹éçš„è³‡æ–™Testing Datasetä¾†åšæŒ‘é¸ï¼Œä¸€æ—¦æŒ‘é¸å®Œå°±ä¸èƒ½å†å»èª¿æ•´ä»»ä½•åƒæ•¸äº†ã€‚\n",
    "\n",
    "\n",
    "### Tensorflowå·¥ä½œæµç¨‹\n",
    "\n",
    "æˆ‘å€‘é€™ä¸€ç¯‡å°‡æœƒä½¿ç”¨Tensorflowå¯¦ä½œæœ€ç°¡å–®çš„å–®å±¤Neurel Networkï¼Œåœ¨é€™ä¹‹å‰æˆ‘å€‘ä¾†çœ‹çœ‹Tensorflowæ˜¯å¦‚ä½•é‹ä½œçš„ï¼Ÿ\n",
    "\n",
    "æ·±åº¦å­¸ç¿’æ˜¯ç”±ä¸€å±¤ä¸€å±¤å¯ä»¥å¾®åˆ†çš„ç¥ç¶“å…ƒæ‰€é€£æ¥è€Œæˆï¼Œæ•¸å­¸ä¸Šå¯ä»¥è¡¨ç¤ºç‚ºå¼µé‡(Tensor)çš„è¡¨ç¤ºå¼ï¼Œæˆ‘å€‘ä¸€èˆ¬è¬›çš„çŸ©é™£é‹ç®—æ˜¯æŒ‡2x2çš„çŸ©é™£é‹ç®—ï¼Œè€Œå¼µé‡(Tensor)å‰‡æ˜¯æ‹“å¯¬åˆ°nç¶­é™£åˆ—åšè¨ˆç®—ï¼Œåœ¨Machine Learningç•¶ä¸­æˆ‘å€‘å¸¸å¸¸éœ€è¦è™•ç†åˆ°ç›¸ç•¶é«˜ç¶­åº¦çš„è¨ˆç®—ï¼Œä¾‹å¦‚ï¼šæœ‰äº”å¼µ28x28çš„å½©è‰²åœ–çš„è¡¨ç¤ºå°±å¿…é ˆä½¿ç”¨åˆ°å››ç¶­å¼µé‡ï¼Œç¬¬ä¸€ç¶­è¡¨ç¤ºç¬¬å¹¾å¼µã€ç¬¬äºŒã€ä¸‰ç¶­è¡¨ç¤ºåœ–ç‰‡çš„å¤§å°ã€ç¬¬å››ç¶­å‰‡è¡¨ç¤ºRGBï¼Œå¦‚æœä½ æ˜¯ç‰©ç†ç³»çš„å­¸ç”Ÿæ‡‰è©²ä¹Ÿå°å¼µé‡ä¸é™Œç”Ÿï¼Œå»£ç¾©ç›¸å°è«–è£¡é ­å¤§é‡çš„ä½¿ç”¨å››ç¶­å¼µé‡é‹ç®—ï¼Œä¸‰ç¶­ç©ºé–“åŠ ä¸€ç¶­æ™‚é–“ã€‚\n",
    "\n",
    "è€Œåœ¨åšNeurel Networkæ™‚ï¼Œæˆ‘å€‘æœƒæ ¹æ“šéœ€æ±‚ä¸åŒè¨­è¨ˆä¸åŒå½¢å¼ä½†åˆç†çš„æµç¨‹(Flow)ï¼Œå†ä½¿ç”¨æ•¸æ“šä¾†è¨“ç·´æˆ‘çš„Modelã€‚æ‰€ä»¥ï¼Œé€™å°±æ˜¯Tensorflowå‘½åç”±ä¾†ï¼šTensor+Flowã€‚\n",
    "\n",
    "å› æ­¤ï¼Œä¸€é–‹å§‹è¦å…ˆè¨­è¨ˆModelçš„çµæ§‹ï¼Œé€™åœ¨Tensorflowè£¡é ­ç¨±ç‚ºGraphï¼ŒGraphçš„ä½œç”¨æ˜¯äº‹å…ˆæ±ºå®šNeurel Networkçš„çµæ§‹ï¼Œæ±ºå®šNeuronè¦æ€éº¼é€£æ¥ï¼Ÿæ±ºå®šå“ªä¸€äº›çª—å£æ˜¯å¯ä»¥ç”±å¤–éƒ¨ç½®æ”¾æ•¸æ“šçš„ï¼Ÿæ±ºå®šå“ªä¸€äº›è®Šæ•¸æ˜¯å¯ä»¥è¢«è¨“ç·´çš„ï¼Ÿå“ªä¸€äº›è®Šæ•¸æ˜¯ä¸å¯ä»¥è¢«è¨“ç·´çš„ï¼Ÿå®šç¾©å°‡è¦æ€éº¼æ¨£å„ªåŒ–é€™å€‹ç³»çµ±ï¼Ÿ...ç­‰ç­‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_graph = tf.Graph() # Initialize a new graph\n",
    "\n",
    "with my_graph.as_default(): # Create a scope to build graph\n",
    "    # ...\n",
    "    # detail of building graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphåªæ˜¯ä¸€å€‹çµæ§‹ï¼Œå®ƒä¸å…·æœ‰æœ‰æ•ˆçš„è³‡è¨Šï¼Œè€Œç•¶æˆ‘å€‘å®šç¾©å®ŒæˆGraphä¹‹å¾Œï¼Œæ¥ä¸‹ä¾†æˆ‘å€‘éœ€è¦å‰µé€ ä¸€å€‹ç’°å¢ƒå«åšSessionï¼ŒSessionæœƒå°‡Graphçš„çµæ§‹è¤‡è£½ä¸€ä»½ï¼Œç„¶å¾Œå†æ”¾å…¥è³‡è¨Šé€²è¡ŒTrainingæˆ–æ˜¯é æ¸¬ç­‰ç­‰ï¼Œå› æ­¤Sessionæ˜¯å…·æœ‰æœ‰æ•ˆè³‡è¨Šçš„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=my_graph) as sess: # Copy graph into session\n",
    "    # ...\n",
    "    # detail of doing machine learning  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é‚„æœ‰å¦å¤–ä¸€ç¨®å¯«æ³•ä¹Ÿæ˜¯ç›¸åŒä½œç”¨çš„ï¼Œæˆ‘å€‹äººæ¯”è¼ƒå–œæ­¡ä¸‹é¢é€™ç¨®å¯«æ³•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_session = tf.Session(graph=my_graph)\n",
    "my_session.run(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflowçš„åŸºæœ¬ã€Œå¼µé‡ã€å…ƒç´ \n",
    "\n",
    "æ¥ä¸‹ä¾†æˆ‘å€‘å°±ä¾†çœ‹çœ‹æœ‰å“ªäº›æ§‹æˆGraphçš„åŸºæœ¬å…ƒç´ å¯ä»¥ä½¿ç”¨ã€‚\n",
    "\n",
    "(1) å¸¸æ•¸å¼µé‡ï¼š\n",
    "\n",
    "ä¸€é–‹å§‹ä¾†çœ‹çœ‹ã€Œå¸¸æ•¸å¼µé‡ã€ï¼Œå¸¸æ•¸æŒ‡çš„æ˜¯åœ¨Modelä¸­ä¸æœƒæ”¹è®Šçš„æ•¸å€¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tf.constant([1, 2, 3, 4, 5, 6, 7], dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) è®Šæ•¸å¼µé‡ï¼š\n",
    "\n",
    "èˆ‡å¸¸æ•¸æˆªç„¶ä¸åŒçš„å°±æ˜¯è®Šæ•¸ï¼Œã€Œè®Šæ•¸å¼µé‡ã€æ˜¯æŒ‡åœ¨è¨“ç·´ç•¶ä¸­å¯ä»¥æ”¹è®Šçš„å€¼ï¼Œä¸€èˆ¬ã€Œè®Šæ•¸å¼µé‡ã€æœƒç”¨ä½œæ–¼Machine Learningéœ€è¦è¢«è¨“ç·´çš„åƒæ•¸ï¼Œå¦‚æœä½ æ²’æœ‰ç‰¹åˆ¥è¨­å®šï¼Œåœ¨æœ€ä½³åŒ–çš„éç¨‹ä¸­ï¼ŒTensorflowæœƒè‡ªå‹•èª¿æ•´ã€Œè®Šæ•¸å¼µé‡ã€çš„æ•¸å€¼ä¾†æœ€ä½³åŒ–ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tf.Variable( tf.truncated_normal(shape=(3,5)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å› ç‚ºè®Šæ•¸é€šå¸¸æ˜¯æœªçŸ¥ä¸”å¾…å„ªåŒ–çš„åƒæ•¸ï¼Œæ‰€ä»¥æˆ‘å€‘ä¸€èˆ¬æœƒä½¿ç”¨Initalizerä¾†è¨­å®šå®ƒçš„åˆå§‹å€¼ï¼Œ`tf.truncated_normal(shape=(3,5))`æœƒéš¨æ©Ÿç”¢ç”Ÿå¤§å°3x5çš„çŸ©é™£ï¼Œå®ƒçš„å€¼å‘ˆå¸¸æ…‹åˆ†ä½ˆä½†åªå–å…©å€‹æ¨™æº–å·®ä»¥å…§çš„æ•¸å€¼ã€‚\n",
    "\n",
    "å¦‚æœä»Šå¤©ä½ æƒ³è¦æœ‰ä¸€å€‹ã€Œè®Šæ•¸å¼µé‡ã€ä½†æ˜¯åˆä¸å¸Œæœ›å®ƒå› ç‚ºæœ€ä½³åŒ–è€Œæ”¹è®Šï¼Œé€™æ™‚ä½ è¦ç‰¹åˆ¥æŒ‡å®š`trainable`ç‚º`False`ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tf.Variable(5, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) ç½®æ”¾å¼µé‡ï¼š\n",
    "\n",
    "å¦å¤–æœ‰ä¸€äº›å¼µé‡è² è²¬æ“”ä»»è¼¸å…¥çª—å£çš„è§’è‰²ï¼Œç¨±ç‚ºPlaceholderã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tf.placeholder(tf.float32, shape=(None,1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å› ç‚ºæˆ‘å€‘åœ¨è¨“ç·´ä¹‹å‰é‚„å°šæœªçŸ¥é“Dataçš„æ•¸é‡ï¼Œæ‰€ä»¥é€™è£¡ä½¿ç”¨Noneä¾†è¡¨ç¤ºæœªçŸ¥ã€‚`tf.placeholder`åœ¨Graphéšæ®µæ˜¯æ²’æœ‰æ•¸å€¼çš„ï¼Œå¿…é ˆç­‰åˆ°Sessionéšæ®µæ‰å°‡æ•¸å€¼çµ¦è¼¸å…¥é€²å»ã€‚\n",
    "\n",
    "(4) æ“ä½œå‹å¼µé‡ï¼š\n",
    "\n",
    "é€™é¡å¼µé‡ä¸¦ä¸å«æœ‰å¯¦éš›æ•¸å€¼ï¼Œè€Œæ˜¯ä¸€ç¨®æ“ä½œï¼Œå¸¸ç”¨çš„ã€Œæ“ä½œå‹å¼µé‡ã€æœ‰å…©ç¨®ï¼Œç¬¬ä¸€ç¨®æ˜¯ä½œç‚ºæœ€ä½³åŒ–ä½¿ç”¨ï¼Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ...\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é¸æ“‡Optimizerå’Œæœ€ä½³åŒ–çš„æ–¹å¼ä¾†å®šç¾©æœ€ä½³åŒ–çš„æ“ä½œæ–¹æ³•ï¼Œä¸Šè¿°çš„ä¾‹å­æ˜¯ä½¿ç”¨learning_rateç‚º0.5çš„Gradient Descentä¾†é™ä½lossã€‚\n",
    "\n",
    "å¦å¤–ä¸€ç¨®æ˜¯åˆå§‹åŒ–çš„æ“ä½œï¼Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é€™ä¸€å€‹æ­¥é©Ÿæ˜¯å¿…è¦çš„ä½†å¸¸å¸¸è¢«å¿½ç•¥ï¼Œé‚„è¨˜å¾—å‰›å‰›æˆ‘å€‘å®šç¾©ã€Œè®Šæ•¸å¼µé‡ã€æ™‚æœ‰ç”¨åˆ°Initalizerï¼Œé€™äº›Initalizeråœ¨Graphå®Œæˆæ™‚é‚„ä¸å…·æœ‰æ•¸å€¼ï¼Œå¿…é ˆä½¿ç”¨`init_op`ä¾†çµ¦äºˆæ•¸å€¼ï¼Œæ‰€ä»¥è¨˜ä½ä¸€å®šè¦æ”¾`init_op`é€²å»Graphè£¡é ­ï¼Œè€Œä¸”å¿…é ˆå…ˆå®šç¾©å®Œæˆæ‰€æœ‰æœƒç”¨åˆ°çš„Initalizerå†ä¾†è¨­å®šé€™å€‹`init_op`ã€‚\n",
    "\n",
    "### Sessionçš„æ“ä½œ\n",
    "\n",
    "ã€Œå¼µé‡ã€å…ƒç´ å…·æœ‰å…©å€‹é¢å‘ï¼šåŠŸèƒ½å’Œæ•¸å€¼ï¼Œåœ¨Graphéšæ®µã€Œå¼µé‡ã€åªå…·æœ‰åŠŸèƒ½ä½†ä¸å…·æœ‰æ•¸å€¼ï¼Œåªæœ‰åˆ°äº†Sessionéšæ®µæ‰é–‹å§‹æœ‰æ•¸å€¼ï¼Œé‚£å¦‚ä½•å°‡é€™äº›æ•¸å€¼å–å‡ºä¾†å‘¢ï¼Ÿæœ‰å…©ç¨®æ–¹æ³•ï¼Œä»¥1+1ç•¶ä½œç¯„ä¾‹ä¾†çœ‹çœ‹ï¼Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.Graph()\n",
    "with g1.as_default():\n",
    "    x = tf.constant(1)\n",
    "    y = tf.constant(1)\n",
    "    sol = tf.add(x,y) # add x and y\n",
    "\n",
    "with tf.Session(graph=g1) as sess: \n",
    "    print(sol) # print tensor, not their value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g1) as sess: \n",
    "    print(sol.eval()) # evaluate their value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "s1 = tf.Session(graph=g1)\n",
    "print(s1.run(sol)) # another way of evaluating value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é‚£å¦‚æœæˆ‘æƒ³ä½¿ç”¨placeholderä¾†åšåˆ°x+yå‘¢ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    x = tf.placeholder(tf.int32)\n",
    "    y = tf.placeholder(tf.int32)\n",
    "    sol = tf.add(x,y) # add x and y\n",
    "\n",
    "s2 = tf.Session(graph=g2)\n",
    "\n",
    "# if x = 2 and y = 3\n",
    "print(s2.run(sol,feed_dict={x: 2,y: 3})) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# if x = 5 and y = 7\n",
    "print(s2.run(sol,feed_dict={x: 5,y: 7})) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å› ç‚ºxå’Œyæ˜¯placeholderï¼Œæ‰€ä»¥å¿…é ˆä½¿ç”¨`feed_dict`ä¾†é¤µå…¥ç›¸é—œè³‡è¨Šï¼Œå¦å‰‡æœƒå ±éŒ¯ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç¬¬ä¸€å€‹Tensorflow Model\n",
    "\n",
    "æœ‰äº†ä»¥ä¸Šçš„èªè­˜æˆ‘å€‘å°±å¯ä»¥ä¾†å»ºç«‹æˆ‘å€‘ç¬¬ä¸€å€‹Modelã€‚\n",
    "\n",
    "ä»¥ä¸‹æˆ‘æœƒä½¿ç”¨ç‰©ä»¶å°å‘çš„å¯«æ³•ï¼Œè®“ç¨‹å¼ç¢¼æ›´æœ‰æ¢ç†ã€‚\n",
    "\n",
    "Machine Learningåœ¨æ“ä½œä¸Šå¯ä»¥æ•´ç†æˆä¸‰å€‹å¤§æ­¥é©Ÿï¼šå»ºæ§‹(Building)ã€è¨“ç·´(Fitting)å’Œæ¨è«–(Inference)ï¼Œæ‰€ä»¥æˆ‘å€‘å°‡æœƒä½¿ç”¨é€™ä¸‰å¤§æ­¥é©Ÿä¾†å»ºè£½æˆ‘å€‘çš„Modelã€‚\n",
    "\n",
    "åœ¨`SimpleLogisticClassification`è£¡é ­ï¼Œã€Œå»ºæ§‹ã€çš„å‹•ä½œåœ¨`__init__`ä¸­æœƒé€²è¡Œï¼Œç”±`build`å‡½å¼ä¾†å»ºç«‹Graphï¼Œå…¶ä¸­æˆ‘å°‡Neurel Networkçš„çµæ§‹åˆ†é›¢å­˜æ–¼`structure`è£¡ã€‚ã€Œè¨“ç·´ã€çš„å‹•ä½œåœ¨`fit`ä¸­é€²è¡Œï¼Œé€™è£¡æ¡ç”¨å‚³çµ±çš„Gradient Descentçš„æ–¹æ³•ï¼Œå°‡æ‰€æœ‰Dataå…¨éƒ¨è€ƒæ…®é€²å»æœ€ä½³åŒ–ï¼Œæœªä¾†æœƒå†ä»‹ç´¹Batch Gradient Descentã€‚æœ€å¾Œï¼Œã€Œæ¨è«–ã€çš„éƒ¨åˆ†åœ¨`predict`å’Œ`evaluate`ä¸­é€²è¡Œã€‚\n",
    "\n",
    "`SimpleLogisticClassification`å°‡æœƒå»ºæ§‹ä¸€å€‹åªæœ‰ä¸€å±¤çš„Neurel Networkï¼Œä¹Ÿå°±æ˜¯èªªæ²’æœ‰Hidden Layerï¼Œç•«å€‹åœ–ã€‚\n",
    "\n",
    "![Simple Logistic Classification](https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/TensorflowTutorial.002.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLogisticClassification(object):\n",
    "    def __init__(self,n_features,n_labels,learning_rate=0.5):\n",
    "        self.n_features = n_features\n",
    "        self.n_labels = n_labels\n",
    "        \n",
    "        self.weights = None\n",
    "        self.biases  = None\n",
    "        \n",
    "        self.graph = tf.Graph() # initialize new graph\n",
    "        self.build(learning_rate) # building graph\n",
    "        self.sess = tf.Session(graph=self.graph) # create session by the graph     \n",
    "    \n",
    "    def build(self,learning_rate):\n",
    "        # Building Graph\n",
    "        with self.graph.as_default():\n",
    "            ### Input\n",
    "            self.train_features = tf.placeholder(tf.float32, shape=(None,self.n_features))\n",
    "            self.train_labels   = tf.placeholder(tf.int32  , shape=(None,self.n_labels))\n",
    "            \n",
    "            ### Optimalization\n",
    "            # build neurel network structure and get their predictions and loss\n",
    "            self.y_,self.loss = self.structure(features=self.train_features,\n",
    "                                                        labels=self.train_labels)\n",
    "            # define training operation\n",
    "            self.train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(self.loss)\n",
    "            \n",
    "            ### Prediction\n",
    "            self.new_features = tf.placeholder(tf.float32, shape=(None,self.n_features))\n",
    "            self.new_labels   = tf.placeholder(tf.int32  , shape=(None,self.n_labels))\n",
    "            self.new_y_,self.new_loss = self.structure(features=self.new_features,\n",
    "                                                       labels=self.new_labels,)\n",
    "            \n",
    "            ### Initialization\n",
    "            self.init_op = tf.global_variables_initializer()\n",
    "            \n",
    "    def structure(self,features,labels):\n",
    "        # build neurel network structure and return their predictions and loss\n",
    "        ### Variable\n",
    "        if (not self.weights) or (not self.biases):\n",
    "            self.weights = {\n",
    "                'fc1': tf.Variable(tf.truncated_normal( shape=(self.n_features,self.n_labels) )),\n",
    "            }\n",
    "            self.biases  = {\n",
    "                'fc1': tf.Variable(tf.zeros( shape=(self.n_labels) )),\n",
    "            } \n",
    "            \n",
    "        ### Structure   \n",
    "        # one fully connected layer\n",
    "        logits = self.getDenseLayer(features,self.weights['fc1'],self.biases['fc1'])\n",
    "        \n",
    "        # predictions\n",
    "        y_ = tf.nn.softmax(logits)\n",
    "        \n",
    "        # loss: softmax cross entropy\n",
    "        loss = tf.reduce_mean(\n",
    "                 tf.nn.softmax_cross_entropy_with_logits(labels=labels,logits=logits))\n",
    "\n",
    "        return (y_,loss)\n",
    "    \n",
    "    def getDenseLayer(self,input_layer,weight,bias,activation=None):\n",
    "        # fully connected layer\n",
    "        x = tf.add(tf.matmul(input_layer,weight),bias)\n",
    "        if activation:\n",
    "            x = activation(x)\n",
    "        return x\n",
    "    \n",
    "    def fit(self,X,y,epochs=10,validation_data=None,test_data=None):\n",
    "        X = self._check_array(X)\n",
    "        y = self._check_array(y)\n",
    "        \n",
    "        self.sess.run(self.init_op)\n",
    "        for epoch in range(epochs):\n",
    "            print(\"Epoch %2d/%2d: \"%(epoch+1,epochs))\n",
    "            \n",
    "            # fully gradient descent\n",
    "            feed_dict = {self.train_features: X, self.train_labels: y}\n",
    "            _ = self.sess.run(self.train_op, feed_dict=feed_dict)\n",
    "            \n",
    "            # evaluate at the end of this epoch\n",
    "            y_ = self.predict(X)\n",
    "            train_loss = self.evaluate(X,y)\n",
    "            train_acc = self.accuracy(y_,y)\n",
    "            msg = \" loss = %8.4f, acc = %3.2f%%\" % ( train_loss, train_acc*100 )\n",
    "            \n",
    "            if validation_data:\n",
    "                val_loss = self.evaluate(validation_data[0],validation_data[1])\n",
    "                val_acc = self.accuracy(self.predict(validation_data[0]),validation_data[1])\n",
    "                msg += \", val_loss = %8.4f, val_acc = %3.2f%%\" % ( val_loss, val_acc*100 )\n",
    "            \n",
    "            print(msg)\n",
    "            \n",
    "        if test_data:\n",
    "            test_acc = self.accuracy(self.predict(test_data[0]),test_data[1])\n",
    "            print(\"test_acc = %3.2f%%\" % (test_acc*100))\n",
    "            \n",
    "    def accuracy(self, predictions, labels):\n",
    "        return (np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))/predictions.shape[0])\n",
    "    \n",
    "    def predict(self,X):\n",
    "        X = self._check_array(X)\n",
    "        return self.sess.run(self.new_y_, feed_dict={self.new_features: X})\n",
    "    \n",
    "    def evaluate(self,X,y):\n",
    "        X = self._check_array(X)\n",
    "        y = self._check_array(y)\n",
    "        return self.sess.run(self.new_loss, feed_dict={self.new_features: X, self.new_labels: y})\n",
    "    \n",
    "    def _check_array(self,ndarray):\n",
    "        ndarray = np.array(ndarray)\n",
    "        if len(ndarray.shape)==1: ndarray = np.reshape(ndarray,(1,ndarray.shape[0]))\n",
    "        return ndarray\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/10: \n",
      " loss =   9.4080, acc = 12.45%, val_loss =   9.3869, val_acc = 12.78%\n",
      "Epoch  2/10: \n",
      " loss =   8.2898, acc = 14.57%, val_loss =   8.2863, val_acc = 14.66%\n",
      "Epoch  3/10: \n",
      " loss =   7.4517, acc = 16.82%, val_loss =   7.4578, val_acc = 16.74%\n",
      "Epoch  4/10: \n",
      " loss =   6.8298, acc = 19.23%, val_loss =   6.8352, val_acc = 19.10%\n",
      "Epoch  5/10: \n",
      " loss =   6.3458, acc = 21.83%, val_loss =   6.3448, val_acc = 21.12%\n",
      "Epoch  6/10: \n",
      " loss =   5.9372, acc = 24.16%, val_loss =   5.9287, val_acc = 23.64%\n",
      "Epoch  7/10: \n",
      " loss =   5.5760, acc = 26.53%, val_loss =   5.5604, val_acc = 25.98%\n",
      "Epoch  8/10: \n",
      " loss =   5.2527, acc = 28.88%, val_loss =   5.2306, val_acc = 28.42%\n",
      "Epoch  9/10: \n",
      " loss =   4.9624, acc = 31.05%, val_loss =   4.9344, val_acc = 30.54%\n",
      "Epoch 10/10: \n",
      " loss =   4.7012, acc = 33.06%, val_loss =   4.6681, val_acc = 32.52%\n",
      "test_acc = 32.77%\n"
     ]
    }
   ],
   "source": [
    "model = SimpleLogisticClassification(n_features=28*28,\n",
    "                                     n_labels=10,\n",
    "                                     learning_rate= 0.5,)\n",
    "model.fit(X=train_data.images,\n",
    "          y=train_data.labels,\n",
    "          epochs=10,\n",
    "          validation_data=(valid_data.images,valid_data.labels),\n",
    "          test_data=(test_data.images,test_data.labels), )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
